{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of S7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futartup/S7-assignment/blob/master/S7-assignment-overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbdg0z4poCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPogbueepoCh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make\n",
        "updates to the weights of the network.\n",
        "\n",
        "Now you might be thinking,\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        ".. figure:: /_static/img/cifar10.png\n",
        "   :alt: cifar10\n",
        "\n",
        "   cifar10\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Loading and normalizing CIFAR10\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yVpodAMpoCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjt4e2TpoCk",
        "colab_type": "text"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tjigo2poCl",
        "colab_type": "code",
        "outputId": "808c3fbb-d7a0-488b-fa75-753ae8e4481f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cj433rtpoCn",
        "colab_type": "text"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daA7bADhpoCo",
        "colab_type": "code",
        "outputId": "b6f664ab-79cc-4f07-bcca-1b6c741fbed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " deer   cat  frog horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHh4eIwr/Avfw8PAYUfw/Y6qmxupytOsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28OpHA_LpoCq",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jjLwLLQpoCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "dropout_value = 0.05\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            #################### Block C1 ###############################\n",
        "            nn.Conv2d(3, 16, 3, padding=1, dilation=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_value),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_value),\n",
        "\n",
        "            nn.MaxPool2d(2,2),\n",
        "            ###########################################################\n",
        "\n",
        "            #################### Block C2 ###############################\n",
        "            nn.Conv2d(32, 64, 3, padding=1, dilation=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_value),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_value),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ###########################################################\n",
        "\n",
        "            #################### Block C3 Depth wise separable convolution ###############################\n",
        "            nn.Conv2d(128, 128, 3, padding=1, dilation=1, bias=False, groups=128),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_value),\n",
        "\n",
        "            nn.Conv2d(128, 256, 1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_value),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ###########################################################\n",
        "\n",
        "            #################### Block C4 ###############################\n",
        "            nn.Conv2d(256, 10, 3, padding=0, bias=False),\n",
        "            nn.AvgPool2d(2),\n",
        "            #############################################################\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEhKY1-4C9vF",
        "colab_type": "code",
        "outputId": "a35b50d9-0131-401b-f41e-d7b3cf598777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = net.to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "         Dropout2d-4           [-1, 16, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 30, 30]           4,608\n",
            "       BatchNorm2d-6           [-1, 32, 30, 30]              64\n",
            "              ReLU-7           [-1, 32, 30, 30]               0\n",
            "         Dropout2d-8           [-1, 32, 30, 30]               0\n",
            "         MaxPool2d-9           [-1, 32, 15, 15]               0\n",
            "           Conv2d-10           [-1, 64, 15, 15]          18,432\n",
            "      BatchNorm2d-11           [-1, 64, 15, 15]             128\n",
            "             ReLU-12           [-1, 64, 15, 15]               0\n",
            "        Dropout2d-13           [-1, 64, 15, 15]               0\n",
            "           Conv2d-14          [-1, 128, 13, 13]          73,728\n",
            "      BatchNorm2d-15          [-1, 128, 13, 13]             256\n",
            "             ReLU-16          [-1, 128, 13, 13]               0\n",
            "        Dropout2d-17          [-1, 128, 13, 13]               0\n",
            "        MaxPool2d-18            [-1, 128, 6, 6]               0\n",
            "           Conv2d-19            [-1, 128, 6, 6]           1,152\n",
            "      BatchNorm2d-20            [-1, 128, 6, 6]             256\n",
            "             ReLU-21            [-1, 128, 6, 6]               0\n",
            "        Dropout2d-22            [-1, 128, 6, 6]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "        Dropout2d-26            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-27            [-1, 256, 4, 4]               0\n",
            "           Conv2d-28             [-1, 10, 2, 2]          23,040\n",
            "        AvgPool2d-29             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 155,408\n",
            "Trainable params: 155,408\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.24\n",
            "Params size (MB): 0.59\n",
            "Estimated Total Size (MB): 3.85\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdw2NNCUpoCu",
        "colab_type": "text"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4xBbDROpoCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-odOrhdpoC2",
        "colab_type": "text"
      },
      "source": [
        "4. Train the network\n",
        "^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkuRfo1IpoC3",
        "colab_type": "code",
        "outputId": "40f73253-ba38-4d45-a2ee-905ece791d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if device == 'cuda':\n",
        "    net = net.cuda()\n",
        "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    # # Save checkpoint.\n",
        "    # acc = 100.*correct/total\n",
        "    # if acc > best_acc:\n",
        "    #     print('Saving..')\n",
        "    #     state = {\n",
        "    #         'net': net.state_dict(),\n",
        "    #         'acc': acc,\n",
        "    #         'epoch': epoch,\n",
        "    #     }\n",
        "    #     if not os.path.isdir('checkpoint'):\n",
        "    #         os.mkdir('checkpoint')\n",
        "    #     torch.save(state, './checkpoint/ckpt.pth')\n",
        "    #     best_acc = acc\n",
        "\n",
        "\n",
        "for epoch in range(1, 15):\n",
        "    print(\"epoch no: \" , epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch no:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.9627809524536133 Batch_id=12499 Accuracy=35.27: 100%|██████████| 12500/12500 [02:45<00:00, 81.07it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2952, Accuracy: 5279/10000 (52.79%)\n",
            "\n",
            "epoch no:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.763702392578125 Batch_id=12499 Accuracy=50.92: 100%|██████████| 12500/12500 [02:41<00:00, 77.17it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0301, Accuracy: 6374/10000 (63.74%)\n",
            "\n",
            "epoch no:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.6468795537948608 Batch_id=12499 Accuracy=58.37: 100%|██████████| 12500/12500 [02:40<00:00, 76.31it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9228, Accuracy: 6828/10000 (68.28%)\n",
            "\n",
            "epoch no:  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.831977128982544 Batch_id=12499 Accuracy=62.67: 100%|██████████| 12500/12500 [02:40<00:00, 78.04it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8467, Accuracy: 7053/10000 (70.53%)\n",
            "\n",
            "epoch no:  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.0339393615722656 Batch_id=12499 Accuracy=65.46: 100%|██████████| 12500/12500 [02:40<00:00, 77.65it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7892, Accuracy: 7258/10000 (72.58%)\n",
            "\n",
            "epoch no:  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.9345431327819824 Batch_id=12499 Accuracy=67.49: 100%|██████████| 12500/12500 [02:39<00:00, 78.17it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7358, Accuracy: 7476/10000 (74.76%)\n",
            "\n",
            "epoch no:  7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.3718387484550476 Batch_id=12499 Accuracy=69.06: 100%|██████████| 12500/12500 [02:40<00:00, 78.12it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6732, Accuracy: 7687/10000 (76.87%)\n",
            "\n",
            "epoch no:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.8857313394546509 Batch_id=12499 Accuracy=70.18: 100%|██████████| 12500/12500 [02:39<00:00, 78.27it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6806, Accuracy: 7647/10000 (76.47%)\n",
            "\n",
            "epoch no:  9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.5731756687164307 Batch_id=12499 Accuracy=71.11: 100%|██████████| 12500/12500 [02:39<00:00, 78.32it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6529, Accuracy: 7788/10000 (77.88%)\n",
            "\n",
            "epoch no:  10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.708113968372345 Batch_id=12499 Accuracy=72.04: 100%|██████████| 12500/12500 [02:39<00:00, 78.42it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6236, Accuracy: 7866/10000 (78.66%)\n",
            "\n",
            "epoch no:  11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.4341981410980225 Batch_id=12499 Accuracy=72.81: 100%|██████████| 12500/12500 [02:41<00:00, 77.17it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6190, Accuracy: 7898/10000 (78.98%)\n",
            "\n",
            "epoch no:  12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.6949042081832886 Batch_id=12499 Accuracy=73.44: 100%|██████████| 12500/12500 [02:43<00:00, 76.66it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6019, Accuracy: 7995/10000 (79.95%)\n",
            "\n",
            "epoch no:  13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.7288402318954468 Batch_id=12499 Accuracy=74.02: 100%|██████████| 12500/12500 [02:41<00:00, 77.61it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5871, Accuracy: 8036/10000 (80.36%)\n",
            "\n",
            "epoch no:  14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.13079524040222168 Batch_id=12499 Accuracy=74.53: 100%|██████████| 12500/12500 [02:41<00:00, 77.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6007, Accuracy: 7945/10000 (79.45%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLrvL_fHpoC5",
        "colab_type": "text"
      },
      "source": [
        "5. Test the network on the test data\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nizbsvw9poC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAx4QPHVpoC8",
        "colab_type": "text"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVLjlssWpoC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8OTHZEApoC_",
        "colab_type": "text"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "Higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABRIDW3lpoDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TV0TXL1poDC",
        "colab_type": "text"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ4-5CESpoDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDdwPBl8poDF",
        "colab_type": "text"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDNFuDEDpoDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}